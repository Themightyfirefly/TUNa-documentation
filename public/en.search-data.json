{"/about/":{"data":{"":"The TUNa chatbot was developed as part of the “Introduction to Prompt Engineering” at TU Berlin."},"title":"About"},"/docs/":{"data":{"":"Introduction Chatbot Design Workflow Design This is the TUNa online documentation. TUNa is a chatbot for TU Berlin students to help them with any questions related to their studies.\nThe chatbot was developed as part of the “Introduction to Prompt Engineering” at TU Berlin."},"title":"_index"},"/docs/chatbot_design/":{"data":{"":"This section presents the overall design of the TUNa chatbot, outlining the core architectural decisions and conceptual principles that guided the development. The design focuses on achieving reliable, domain specific assistance for study organization at TU Berlin while addressing known limitations of large language models, such as hallucinations and sensitivity to ambiguous input. To this end, the chatbot combines a GPT-based language model with a curated knowledge base and a carefully engineered system prompt. The following subsections describe how knowledge is structured, how prompts are designed and iteratively refined, and how these components interact to produce consistent, trustworthy responses aligned with the intended scope and use case of the system."},"title":"Chatbot Design"},"/docs/chatbot_design/knowledge_format/":{"data":{"":"The design of the knowledge base plays a central role in the reliability, efficiency, and maintainability of a chatbot. In TUNa, the knowledge base functions as the exclusive source of verified information and directly influences retrieval quality, response latency, and the likelihood of hallucinations. Consequently, the choice of knowledge formats is not only a matter of content representation but also a technical design decision with measurable effects on system behavior.\nThe main knowledge file format used in this project is Markdown. Markdown offers a strong balance between structural expressiveness and token efficiency. Headings, lists, and concise formatting provide clear semantic boundaries that improve retrieval precision while introducing minimal token overhead. Compared to other formatted documents, Markdown allows relevant sections to be embedded or retrieved with fewer overhead tokens, which positively affects inference speed and reduces context saturation. From a reliability perspective, the explicit structure of Markdown supports grounded responses by clearly separating definitions, procedures, and exceptions, thereby lowering the risk of hallucinations. In addition, Markdown files are easy to read, edit, and version controlable, making them highly maintainable in collaborative development settings, such as in this project.\nPDF files are used selectively when information is only available in this format. From a technical standpoint, PDFs are suboptimal for language model based retrieval. They often contain dense paragraphs, repeated headers, or layout artifacts that increase high token usage without adding semantic value. This can negatively impact retrieval speed and reduce precision, as relevant information may be embedded within large text blocks. Furthermore, the lack of explicit semantic structure increases the risk that the model misinterprets or overgeneralizes content, potentially leading to hallucinations. Nevertheless, PDFs offer high reliability in terms of source authenticity and human-readability and are therefore retained when accuracy to the original document outweighs the disadvantages in efficiency and maintainability.\nJSON represents a contrasting design choice, optimized for machine-readability and strict structural consistency. JSON is highly efficient for representing discrete entities, mappings, and metadata, enabling precise retrieval and minimizing ambiguity at the data level. When used appropriately, this format can reduce hallucinations caused by loosely phrased textual descriptions. However, JSON tends to be token-heavy due to repeated keys and syntax, which can increase context size and slow down inference when large datasets are involved. Moreover, JSON is less suitable for natural language explanations and is harder to maintain for nontechnical contributors, limiting its usefulness for procedural or advisory content.\nPlain text files provide minimal syntactic overhead and can be token-efficient for very short or static information. However, the absence of explicit structure reduces retrieval reliability and makes it harder for the model to distinguish between different types of information, such as conditions, steps, or exceptions. This lack of structure increases the likelihood of ambiguous interpretation and therefore increases hallucinations in more complex queries. Plain text is also less maintainable for growing knowledge bases, as content organization relies entirely on manual conventions rather than formal structure.\nIn summary, the knowledge format choices in TUNa reflect a trade-off between efficiency, reliability, and maintainability. Markdown is the preferred format due to its favorable balance of readability, token efficiency, and structural clarity. PDFs are used only when required by the source, accepting reduced retrieval efficiency in exchange for authoritative accuracy. JSON and plain text are reserved for narrowly defined technical use cases where their specific advantages outweigh their limitations. This deliberate design contributes to stable model behavior, reduced hallucination risk, and scalable maintenance of the knowledge base."},"title":"Knowledge Format"},"/docs/chatbot_design/prompt/":{"data":{"":"The target audience primarily uses natural language rather than structured prompting techniques. Consequently, user inputs are frequently concise or implicitly phrased (e.g., simply asking “registration” without further specification). Relying on the model to infer the correct intent from such sparse input significantly increases the risk of hallucination and misguidance [1]. By implementing different prompting techniques, the system tries to compensate for the ambiguity of natural language, actively interpreting vague queries to ensure robustness regardless of the initial input quality. This design choice aligns with recommendations from recent surveys on robust prompt engineering applications [2] [3] [4].","impact-on-model-behavior#Impact on Model Behavior":"The transition from V1 to V2 resulted in distinct, observable shifts in model behavior. Regarding Ambiguity Handling, whereas V1 tended to assume specific details for vague queries (e.g., assuming a standard deadline for all students), V2 correctly halts generation to request clarification, aligning with the CLAM protocol. In terms of Information Fidelity, the enforcement of the CoV protocol significantly increased the system’s resistance to answering questions not covered by the RAG knowledge base. Finally, the implementation of safety guards ensured that the system maintains a supportive tone without crossing the boundary into unauthorized psychological counseling [13].","methodological-framework-and-applied-techniques#Methodological Framework and Applied Techniques":"To achieve this requisite robustness, the final system prompt was constructed by integrating several established methodological frameworks. Each component addresses a specific shortcoming identified in standard LLM interactions. First, to define the system’s behavior and boundaries, as seen in Figure 2, the prompt adopts the explicit persona of an “Institutional Assistant” (TUNa). While early iterations utilized a metaphorical “Friendly Fish” persona to establish rapport, the final design shifted towards a functional role. Research by Ayach et al. [3] and Wang [5] et al. suggests that explicit role-prompting helps LLMs maintain a consistent tone and effectively suppresses the generic, sometimes biased training data in favor of domain-specific constraints. By defining the assistant as “institutional” rather than purely “conversational”, the chatbot is primed to prioritize neutrality over agreeableness.\nFigure 2: Excerpt from Final System Prompt.\rSecond, to control the depth and precision of generated answers, the prompt structures its instructions according to Bloom’s Taxonomy [6]. This hierarchical approach aligns with the Hierarchical Prompting Taxonomy (HPT) proposed by Budagam et al. [7], which advocates adapting the prompting strategy based on task complexity, with an excerpt shown in Figure 3. Standard prompts often fail to distinguish between simple fact retrieval and complex application of rules. By explicitly commanding the model to categorize tasks, ranging from “Recall” (Level 1) for factual dates to “Application” (Level 4) for procedural guidance, the system can better tailor its reasoning process to the complexity of the user’s request.\nFigure 3: Excerpt from Final System Prompt.\rThird, to mitigate hallucinations, the most highest risk in providing administrative advice, the prompt enforces a Chain-of-Verification (CoV) protocol [8]. The CoV technique counteracts immediate generation by forcing a multi-step reasoning process. The model must first retrieve evidence, evaluate its relevance, and cross-check facts against the retrieval index before explicitly drafting a response.\nFinally, addressing the inherent ambiguity of student queries, the system implements the CLAM framework (Clarification for Ambiguous Questions) [9]. In standard interactions, models often guess the user’s intent to be helpful. The CLAM protocol acts like a gating mechanism where the model is explicitly forbidden from guessing. Instead, it must identify missing variables and ask targeted clarifying questions, as seen below in Figure 4.\nFigure 4: Excerpt from Final System Prompt.\r## The Iteration Process\rThe development of the system prompt was not static but followed an iterative improvement process, evolving from a loose conversational baseline to a strict logic-driven instruction set.\rPhase 1 (Baseline V1) focused primarily on approachability. The “Friendly Fish” (shown in Figure 5) prompt used basic instruction tuning to create a welcoming atmosphere. However, during initial testing, this version lacked mechanisms to handle “Out-of-Distribution” (OOD) queries, often leading to plausible but incorrect advice when knowledge was missing:\nFigure 5: Excerpt from Final System Prompt.\rPhase 2 (Logic Injection) addressed these failures by introducing explicit reasoning steps. The prompt was expanded to include “Negative Constraints” instructions defining what the model must not do [10]. This phase strictly defined the boundary between verified retrieval and general conversation.\nPhase 3 (Safety Integration) incorporated specific protocols for crisis detection. Drawing on ethical guidelines for LLM-based suicide intervention [11], the prompt was modified to strictly separate empathy from assistance. While the baseline V1 risked engaging in therapeutic role-play, which is ethically problematic for non-medical AI [12], the final V2 prompt, seen in Figure 6, enforces a “Dissociated Empathy” protocol. This ensures that crisis queries trigger an immediate “Stop-Sequence”, prioritizing user safety over conversational continuity.\nFigure 6: Excerpt from Final System Prompt.","references#References":"[1] - L. Huang et al., “A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions,” ACM Transactions on Information Systems, vol. 43, no. 2, pp. 1–55, 2025.\n[2] - P. Sahoo, A. K. Singh, S. Saha, V. Jain, S. Mondal, and A. Chadha, “A systematic survey of prompt engineering in large language models: Techniques and applications,” arXiv preprint arXiv:2402.07927, 2024.\n[3] - F. Ayach et al., “Generating proto-personas through prompt engineering: a case study on efficiency, effectiveness and empathy,” arXiv preprint arXiv:2507.08594, 2025.\n[4] - T. Debnath, M. N. A. Siddiky, M. E. Rahman, P. Das, and A. K. Guha, “A comprehensive survey of prompt engineering techniques in large language models,” TechRxiv, 2025.\n[5] - R. Wang et al., “Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models,” in Findings of the Association for Computational Linguistics: NAACL 2024, K. Duh, H. Gomez, and S. Bethard, Eds., Mexico City, Mexico: Association for Computational Linguistics, June 2024, pp. 2243–2255. doi: 10.18653/v1/2024.findings-naacl.145.\n[6] - J. Jackson, “Higher order prompting: Applying Bloom’s revised taxonomy to the use of large language models in higher education,” Studies in Technology Enhanced Learning, vol. 4, no. 1, 2025.\n[7] - D. Budagam, K. Sankalp, A. Kumar, V. Jain, and A. Chadha, “Hierarchical prompting taxonomy: A universal evaluation framework for large language models,” arXiv preprint arXiv:2406.12644, 2024.\n[8] - S. Dhuliawala et al., “Chain-of-verification reduces hallucination in large language models,” in Findings of the association for computational linguistics: ACL 2024, 2024, pp. 3563–3578.\n[9] - L. Kuhn, Y. Gal, and S. Farquhar, “Clam: Selective clarification for ambiguous questions with generative language models,” arXiv preprint arXiv:2212.07769, 2022.\n[10] - Y. Ban, R. Wang, T. Zhou, M. Cheng, B. Gong, and C.-J. Hsieh, “Understanding the Impact of Negative Prompts: When and How Do They Take Effect?,” in european conference on computer vision, 2024, pp. 190–206.\n[11] - G. Holmes, B. Tang, S. Gupta, S. Venkatesh, H. Christensen, and A. Whitton, “Applications of large language models in the field of suicide prevention: Scoping review,” Journal of Medical Internet Research, vol. 27, p. e63126, 2025.\n[12] - M. Ostermann, O. Freyer, F. G. Verhees, J. N. Kather, and S. Gilbert, “If a therapy bot walks like a duck and talks like a duck then it is a medically regulated duck,” npj Digital Medicine, vol. 8, no. 1, p. 741, 2025.\n[13] - A. M. Schoene and C. Canca, “For Argument’s Sake, Show Me How to Harm Myself!’: Jailbreaking LLMs in Suicide and Self-Harm Contexts,” arXiv preprint arXiv:2507.02990, 2025."},"title":"System Prompt"},"/docs/introduction/":{"data":{"":"Universities rely on complex and widely distributed digital infrastructures to manage study organization, academic regulations and other administrative processes, with the intention of providing transparency and enabling self service. While these systems have distinct use cases, they also result in a highly fragmented and scattered information network for students. This can be also seen at TU Berlin, where information on exams, course registrations, study regulations and other advisory services are spread across multiple platforms and documents. Producing difficulties for students to quickly find and identify relevant answers in their everyday student organization.\nThis project addresses these challenges through the development of TUNa (TU Navigator), a GPT-based, domain specific chatbot designed to support students in organizing their studies at TU Berlin. TUNa aims to centralize access to study related information by providing reliable answers to frequent student queries.\nThe scope of this helper is intentionally limited to study related organizational processes at the TU Berlin, which include the topics of examinations, course and exam registrations, thesis submission, study regulations, learning platforms such as ISIS and MOSES, Erasmus programs and relevant administrative contacts and locations. By design choices, topics outside of this domain are deliberately excluded to reduce ambiguity and prevent hallucinations to ensure that the responses are grounded and verified.\nThe intended use case of TUNa is to serve as a information and organizing assistant for student of TU Berlin, who need quick and reliable information without first browsing multiple different university websites or contacting administrative offices for their questions. The chatbot is not intended to replace official advisory services but to complement them.\nThe primary project goal is to evaluate whether a carefully scoped, GPT-based chatbot can reduce the time and effort students spend searching for study related information while maintaining a high level of correctness and trustworthiness. A secondary goal is exploring how prompt engineering techniques, such as role prompting, selective clarification, and verification driven reasoning, can be combined to achieve robust model behavior in a high stakes, administrative domain. Accordingly, this report documents both the technical design decisions and the empirical evaluation of the system’s effectiveness compared to a general purpose GPT baseline."},"title":"Introduction"},"/docs/workflow/":{"data":{"":"The large number of information found on the TU Berlin website leads to the question of how a knowledge base can be generated in an efficient and high quality way. In this chapter we will take a closer at what tools were utilised and how the developement process was organised."},"title":"Workflow Design"},"/docs/workflow/chatbot_settings_and_prompt_deployment/":{"data":{"":"The chatbot settings can be found in the General_Settings.md file. These settings have to be copied line by line, as there is no automatic upload in the online GPT editor.\nThe prompt, discussed in detail in the System Prompt section, can be found in the system_prompt directory. The prompt must be copied into the online editor, just like the general settings."},"title":"Chatbot Settings and Prompt Deployment"},"/docs/workflow/future_use/":{"data":{"":"Additionally to the knowledge, the final TUNa release on GitHub also includes the project sources. These sources can be used by future project groups to further work on the chatbot or to create new chatbots.\nShould future project groups decide to build upon the existing project and plan to use GitHub, they can also fork the TUNa repository, which will enable the direct execution of the TUNa workflow without the need for additional setup steps.\nThe information regarding chatbot development included in this documentation has also been made available through the TUNa website at https://themightyfirefly.github.io/TUNa-documentation/. As the website is directly linked in the main README file inside the TUNa GitHub repository, it allows future project groups to quickly access information regarding the developement of the chatbot. We want to provide the knowledge we have gained throughout the development of TUNa, so that future project groups can build upon our chatbot and the methods we have utilised."},"title":"Future Use of the GitHub project"},"/docs/workflow/general_github_setup/":{"data":{"":"We quickly realised the value of version control. Even small changes in prompts and knowledge files can affect the quality of the chatbot answers. Using git as version control allows us to track all changes and revert to older versions in case the performance declines. A great help during the work with local git is the online git documentation.\nTo enable cooperative work on the chatbot sources and provide an easy to use webinterface we used GitHub as a git server provider. We have created a TUNa repository that allows every contributer to pull the newest sources and push additional knowledge or other changes from their local computer to the server for everyone to use. Additionally, README files within the repository provide extra information on how to use the provided tools."},"title":"General GitHub Setup"},"/docs/workflow/github_workflow/":{"data":{"":"The GitHub server allows the creation of workflow files that automatically execute on certain events. We utilise this tool to generate the actual knowledge files that are to be uploaded to the Custom GPT. Once changes are pushed to the server, the custom workflow will execute the tools discussed in the following chapters. All executed workflows can be seen in the GitHub Actions tab in the repository (see below). By clicking on the most recent execution of the workflow we can see the chatbot knowledge that was created by the last execution of the workflow. All users with collaboration access to the TUNa repository can download the chatbot knowledge as a zip archive. Other users can access the knowledge through the final TUNa release on GitHub.\nAfter obtaining the knowledge zip archive, users can extract the archive and directly upload all knowledge files to the custom GPT. We recommend to delete and upload all knowledge files after any changes, as it ensures that all changes are included and prevents unexpected behaviour."},"title":"GitHub Workflow"},"/docs/workflow/knowledge_file_gathering/":{"data":{"":"The previously discussed workflow gathers knowledge files and provides them as a combined zip archive. In order to do so, it follows these rules:\nGather all file paths within the Knowledge directory Exclude python files and their requirements.txt files Exclude files or directories with the following keywords in their name or path “combine_”, as such directories will be used for pdf combining. “survey”, as any survey related documents should not be part of the knowledge “StuPos”, as the generated combined StuPo is currently too large This leaves the workflow with all of our markdown, pdf and json files which it can copy into a temporary directory. The directory with all of these knowledge files is then uploaded as an artifact and provided as a download to the user within the GitHub actions tab."},"title":"Knowledge File Gathering"},"/docs/workflow/pdf_file_combination/":{"data":{"":"To aid flexibility and maintainability of the gathered pdf resources, we created a python script that combines all pdf files within a given directory. Inside the script, a maximum file size is defined. This can be used to prevent knowledge files from getting too large. The script will combine all pdf files in the given directory into as few files as possible while maintaining the maximum file size.\nThe script is executed by the GitHub workflow, which applies the script to all directories that include “combine_” in their name. An example for how to utilise this tool can be found in the Erasmus knowledge. Here, brochures including all faculties’ exchange cooperations have been downloaded from the TU Berlin website and copied into a directory called combine_Incoming_Erasmus_Brochure. On execution the GitHub workflow will combine all of these brochures into one pdf file called “Incoming_Erasmus_Brochure.pdf”. By utilising this tool, we are able to reduce the number of knowledge files, while keeping the pdf knowledge files customisable."},"title":"PDF File Combination"},"/docs/workflow/stupo_crawler/":{"data":{"":"We have utilised the python package beautiful soup in order to automatically get information on all of the study programs. There are 144 study programs at the TU Berlin. Adding each of the study programs including any kind of detailed information by hand to the knowledge is not achievable in the extend of one semester. The python crawler that we have written allows us to scan through the list of study programs and gather information to each of them. It extracts the links to the study program websites and scans through them to find any kind of useful text. The script tries to maintain the structure of the webpage as well as possible, while combining the information of all study program websites in one markdown file. This markdown file is seperated by headings with the names of the study programs.\nThe GitHub workflow executes the python crawler and uploads the generated markdown file. The crawler also downloads all available StuPOs and combines them into one large pdf. Unfortunately, the file is too large which leads to the chatbot hallucinating instead of properly accessing the correct StuPo. Future work could investigate how indexing can be used to improve the use of very large knowledge files. Due to the time constraint we decided to not persue this issue and to not include the StuPO pdf in our knowledge. This is why the workflow ignores the combined StuPO pdf file and does not upload it.\nUtilising crawlers or scrapers to gather knowledge files plays a large role in the maintainability of a knowledge base. Eventually information will change. Having the option to gather all current information from the TUB websites by the press of a button is hugely beneficial to the maintainers of a chatbot."},"title":"StuPo Crawler"}}